{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to stream runnables\n",
    "Streaming is critical in making applications based on LLMs feel responsive to end-users. This interface provider 2 general approches:\n",
    "1. sync `stream` and async `astream`: a default implementation of streaming that streams the final output from the chain.\n",
    "2. async `astream_events` and async `astream_log`: these provide a way to stream both intermediate steps and final output from the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "model = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Stream\n",
    "NOTE: select from working environment it meant if model streaming run on async function, you should use `astream` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| sky| appears| blue| to| our| eyes| during| the| daytime|,| but| it| can| take| on| hues| of| red|,| orange|,| and| purple| during| sunrise| and| sunset|.||"
     ]
    }
   ],
   "source": [
    "# sync stream API:\n",
    "chunks = []\n",
    "for chunk in model.stream(\"what color is the sky? Answer in short sentence.\"):\n",
    "  chunks.append(chunk)\n",
    "  print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| sky| appears| blue| to| our| eyes|,| but| it| can| also| appear| other| colors| depending| on| the| time| of| day| and| atmospheric| conditions|.||"
     ]
    }
   ],
   "source": [
    "# async astream API:\n",
    "chunks = []\n",
    "async for chunk in model.astream(\"what color is the sky? Answer in short sentence.\"):\n",
    "  chunks.append(chunk)\n",
    "  print(chunk, end=\"|\", flush=True)\n",
    "  # print(chuck.content, end=\"|\", flush=True) # depending on models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]\n",
    "# Some model, you can got back something called AIMessageChunk\n",
    "# from langchain_core.messages.ai import AIMessageChunk\n",
    "# AIMessageChunk(content=\"The\", id='run-b36bea64-5511-4d7a-b6a3-a07b3db0c8e7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here|'s| one|:\n",
      "\n",
      "|Why| did| the| par|rot| go| to| the| doctor|?\n",
      "\n",
      "|Because| it| had| a| f|owl| temper|!\n",
      "\n",
      "|Hope| that| made| you| squ|awk| with| laughter|!||"
     ]
    }
   ],
   "source": [
    "# Chains\n",
    "# involves more step using LangChain Expression Language (LCEL): combines a prompt, model and a parser and verify that streaming works\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"parrot\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 653}]}\n",
      "{'countries': [{'name': 'France', 'population': 653451}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 467527}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}, {'name': 'Japan', 'population': 128}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}, {'name': 'Japan', 'population': 128000}]}\n",
      "{'countries': [{'name': 'France', 'population': 65345100}, {'name': 'Spain', 'population': 46752716}, {'name': 'Japan', 'population': 128000000}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = model | JsonOutputParser()  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "async for text in chain.astream(\n",
    "  \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "  'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "  \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "  print(text, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "# Any steps in the chain that operate on finalized inputs rather than on input streams can break streaming functionality via stream or astream.\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# A function that operates on finalized inputs\n",
    "# Streaming will not work with this function\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France|Spain|Japan|"
     ]
    }
   ],
   "source": [
    "# Solve the problem using generator functions\n",
    "# generator functions (yield): a function that returns an iterator and can be paused and resumed\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "  \"\"\"A function that operates on input streams.\"\"\"\n",
    "  country_names_so_far = set()\n",
    "\n",
    "  async for input in input_stream:\n",
    "    if not isinstance(input, dict):\n",
    "      continue\n",
    "\n",
    "    if \"countries\" not in input:\n",
    "      continue\n",
    "\n",
    "    countries = input[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "      continue\n",
    "\n",
    "    for country in countries:\n",
    "      name = country.get(\"name\")\n",
    "      if not name:\n",
    "        continue\n",
    "      if name not in country_names_so_far:\n",
    "        yield name\n",
    "        country_names_so_far.add(name)\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "  \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "  'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "  \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "  print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='harrison likes spicy food'),\n",
       "  Document(page_content='harrison worked at kensho')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-streaming components\n",
    "# some built-in components like Retriever, which fetches data from the internet, do not support streaming\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "# pip install faiss-gpu or pip install faiss-cpu\n",
    "vectorstore = FAISS.from_texts(\n",
    "  [\"harrison worked at kensho\", \"harrison likes spicy food\"],\n",
    "  # embedding=OpenAIEmbeddings(),\n",
    "  embedding=OllamaEmbeddings(model=\"llama3\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "chunks = [chunk for chunk in retriever.stream(\"where did harrison work?\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based| on| the| given| context|,| Harrison| worked| at| Kens|ho|.\n",
      "\n",
      "|Here| are| three| made|-up| sentences| about| Kens|ho|:\n",
      "\n",
      "|K|ens|ho| is| a| trendy| restaurant| that| serves| an| array| of| international| dishes| with| a| focus| on| bold| flavors| and| spices|.| The| vibrant| atmosphere| and| eclectic| decor| make| it| a| popular| spot| for| food|ies| and| social|ites| alike|.| As| the| go|-to| place| for| spicy| food| enthusiasts|,| Kens|ho|'s| chefs| are| always| experimenting| with| new| hot| sauces| and| marin|ades| to| tantal|ize| taste| buds|.||"
     ]
    }
   ],
   "source": [
    "# But we can use RunnablePassthrough to convert the non-streaming component to a streaming component\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "retrieval_chain = (\n",
    "  {\n",
    "    \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "  }\n",
    "  | prompt\n",
    "  | model\n",
    "  | StrOutputParser()\n",
    ")\n",
    "for chunk in retrieval_chain.stream(\"Where did harrison work? \" \"Write 3 made up sentences about this place.\"):\n",
    "  print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Stream Events\n",
    "for langchain v2\n",
    "`astream_events` API:\n",
    "- use `async` in the code\n",
    "- callbacks if defining custom functions / runnables\n",
    "- Whenever using runnables without LCEL, make sure to call `.astream() `on LLMs rather than `.ainvoke` to force the LLM to stream tokens.\n",
    "Event Type Reference: [Link](https://python.langchain.com/v0.2/docs/how_to/streaming/#event-reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poom/Desktop/learning/langchain/env/lib/python3.9/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "# Chat Model\n",
    "events = []\n",
    "async for event in model.astream_events(\"hello\", version=\"v2\"):\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_llm_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'Ollama',\n",
       "  'tags': [],\n",
       "  'run_id': 'd55416c6-b085-4998-9491-c4102c34a758',\n",
       "  'metadata': {}},\n",
       " {'event': 'on_llm_stream',\n",
       "  'run_id': 'd55416c6-b085-4998-9491-c4102c34a758',\n",
       "  'name': 'Ollama',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'data': {'chunk': 'Hello'}},\n",
       " {'event': 'on_llm_stream',\n",
       "  'run_id': 'd55416c6-b085-4998-9491-c4102c34a758',\n",
       "  'name': 'Ollama',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'data': {'chunk': '!'}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_llm_stream',\n",
       "  'run_id': 'd55416c6-b085-4998-9491-c4102c34a758',\n",
       "  'name': 'Ollama',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'data': {'chunk': ''}},\n",
       " {'event': 'on_llm_end',\n",
       "  'data': {'output': {'generations': [[{'text': \"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\",\n",
       "       'generation_info': {'model': 'llama3',\n",
       "        'created_at': '2024-06-12T17:23:09.985896086Z',\n",
       "        'response': '',\n",
       "        'done': True,\n",
       "        'done_reason': 'stop',\n",
       "        'context': [128006,\n",
       "         882,\n",
       "         128007,\n",
       "         198,\n",
       "         198,\n",
       "         15339,\n",
       "         128009,\n",
       "         128006,\n",
       "         78191,\n",
       "         128007,\n",
       "         198,\n",
       "         198,\n",
       "         9906,\n",
       "         0,\n",
       "         1102,\n",
       "         6,\n",
       "         82,\n",
       "         6555,\n",
       "         311,\n",
       "         3449,\n",
       "         499,\n",
       "         13,\n",
       "         2209,\n",
       "         1070,\n",
       "         2555,\n",
       "         358,\n",
       "         649,\n",
       "         1520,\n",
       "         499,\n",
       "         449,\n",
       "         11,\n",
       "         477,\n",
       "         1053,\n",
       "         499,\n",
       "         1093,\n",
       "         311,\n",
       "         6369,\n",
       "         30,\n",
       "         128009],\n",
       "        'total_duration': 17196226590,\n",
       "        'load_duration': 11180405296,\n",
       "        'prompt_eval_count': 11,\n",
       "        'prompt_eval_duration': 1856001000,\n",
       "        'eval_count': 26,\n",
       "        'eval_duration': 4112287000},\n",
       "       'type': 'Generation'}]],\n",
       "    'llm_output': None}},\n",
       "  'run_id': 'd55416c6-b085-4998-9491-c4102c34a758',\n",
       "  'name': 'Ollama',\n",
       "  'tags': [],\n",
       "  'metadata': {}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'},\n",
       "  'name': 'RunnableSequence',\n",
       "  'tags': [],\n",
       "  'run_id': '20d1a9f7-51bf-4e11-8e27-4692baafa44d',\n",
       "  'metadata': {}},\n",
       " {'event': 'on_llm_start',\n",
       "  'data': {'input': {'prompts': ['output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`']}},\n",
       "  'name': 'Ollama',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'run_id': '76d04bb5-ff65-47eb-91f1-4055f600988d',\n",
       "  'metadata': {}},\n",
       " {'event': 'on_llm_stream',\n",
       "  'data': {'chunk': GenerationChunk(text='Here')},\n",
       "  'run_id': '76d04bb5-ff65-47eb-91f1-4055f600988d',\n",
       "  'name': 'Ollama',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'metadata': {}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "# Chain\n",
    "chain = model | JsonOutputParser()\n",
    "events = [\n",
    "  event async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "  )\n",
    "]\n",
    "# This will start with 3 events:\n",
    "# 1. The chain (model + parser), 2. The model, 3. The parser\n",
    "events[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser chunk: {}\n",
      "Parser chunk: {'countries': []}\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Parser chunk: {'countries': [{'name': ''}]}\n",
      "Parser chunk: {'countries': [{'name': 'France'}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 670}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 670000}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': ''}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain'}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain', 'population': 467}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain', 'population': 467547}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain', 'population': 46754794}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain', 'population': 46754794}, {}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain', 'population': 46754794}, {'name': ''}]}\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67000000}, {'name': 'Spain', 'population': 46754794}, {'name': 'Japan'}]}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# list output stream events, ignore start event, end event and events from chains\n",
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "  \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "  'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "  \"Each country should have the key `name` and `population`\",\n",
    "  version=\"v2\",\n",
    "):\n",
    "  kind = event[\"event\"]\n",
    "  if kind == \"on_chat_model_stream\":\n",
    "    print(\n",
    "      f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "      flush=True,\n",
    "    )\n",
    "  if kind == \"on_parser_stream\":\n",
    "    print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "  num_events += 1\n",
    "  if num_events > 100:\n",
    "    # Truncate the output\n",
    "    print(\"...\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_parser_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'my_parser', 'tags': ['seq:step:2'], 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'metadata': {}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': []}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': ''}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France'}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 653}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 653552}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 653552000}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 653552000}, {}]}}}\n",
      "{'event': 'on_parser_stream', 'run_id': 'c8f8e749-51d6-48a0-9253-ae5f5eafa883', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 653552000}, {'name': ''}]}}}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# filter events\n",
    "# You can filter by either component name, component tags or component type.\n",
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "# 1. By Name\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "  \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "  'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "  \"Each country should have the key `name` and `population`\",\n",
    "  version=\"v2\",\n",
    "  include_names=[\"my_parser\"],\n",
    "):\n",
    "  print(event)\n",
    "  max_events += 1\n",
    "  if max_events > 10:\n",
    "    # Truncate output\n",
    "    print(\"...\")\n",
    "    break\n",
    "# 2. By Type\n",
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "  {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "  'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "  version=\"v2\",\n",
    "  include_types=[\"chat_model\"],\n",
    "):\n",
    "  print(event)\n",
    "  max_events += 1\n",
    "  if max_events > 10:\n",
    "    # Truncate output\n",
    "    print(\"...\")\n",
    "    break\n",
    "\n",
    "# 3. By Tags\n",
    "chain = (model | JsonOutputParser()).with_config({\"tags\": [\"my_chain\"]})\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "  'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "  version=\"v2\",\n",
    "  include_tags=[\"my_chain\"],\n",
    "):\n",
    "  print(event)\n",
    "  max_events += 1\n",
    "  if max_events > 10:\n",
    "      # Truncate output\n",
    "      print(\"...\")\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-streaming components: While such components can break streaming of the final output when using astream, astream_events will still yield streaming events from intermediate steps that support streaming!\n",
    "# ref: https://python.langchain.com/v0.2/docs/how_to/streaming/#non-streaming-components-1\n",
    "\n",
    "# Propagating Callbacks: when using invoking runnables inside your tools\n",
    "# ref: https://python.langchain.com/v0.2/docs/how_to/streaming/#propagating-callbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
